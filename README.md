# MCP OS Demo (LP One-Pager)

An **MCP (Model Context Protocol)â€“based Operating System** that automatically extracts, computes, and summarizes portfolio company financial data into branded LP one-pagers using a **multi-agent non-deterministic workflow** in which agents orchestrate MCP tools via the MCP protocol, and those tools interact with different data sources (files, databases, APIs).

> ğŸ“– **For detailed documentation, see [PRD.md](prd.md)**

---

## Quick Start

### 1. Start Database

```bash
docker compose up -d
```

Postgres URL: `postgres://mcp:mcp@localhost:5433/mcp_ctx`

### 2. Set Up Environment Variables

Create a `.env` file in the project root:

```bash
cp .env.example .env
```

Edit `.env` with your configuration:

```bash
# Database connection
DB_URL=postgres://mcp:mcp@localhost:5433/mcp_ctx

# Embedding Model (optional, default: Xenova/all-MiniLM-L6-v2 - local model, no API key needed)
EMBEDDING_MODEL=Xenova/all-MiniLM-L6-v2

# MCP Server Configuration
MCP_SERVER_URL=http://localhost:3333/mcp

# LangChain Agent Configuration (optional, for LLM content generation)
OPENAI_API_KEY=your_openai_api_key_here  # Optional - enables LLM-generated content
LLM_MODEL=gpt-3.5-turbo                  # Optional - OpenAI model to use (default: gpt-3.5-turbo)
                                         # All agents (IngestionAgent, KPIComputationAgent, ContentGenerationAgent) use this model
                                         # Supported: gpt-3.5-turbo, gpt-4, gpt-4-turbo, etc.

# Workflow Configuration (optional)
DEAL_ID=00000000-0000-0000-0000-000000000001
COMPANY_NAME=Acme Software, Inc.
PERIOD_END=2025-09-30
DATA_DIR=./data
```

**Note:** 
- Embeddings are generated using **local models** (ChromaDB) - no API key required!
- `OPENAI_API_KEY` is **optional** - only needed for LLM-generated investment thesis and risks
- If `OPENAI_API_KEY` is not set, the system will use fallback content
- `LLM_MODEL` configures the OpenAI model used by all agents (IngestionAgent, KPIComputationAgent, ContentGenerationAgent)
- Default model is `gpt-3.5-turbo`; can be changed to `gpt-4`, `gpt-4-turbo`, etc.

### 3. Start MCP Server

The server automatically loads environment variables from `.env` if it exists:

```bash
npx tsx mcp-lp-tools-server.ts
```

On first run, the embedding model will be downloaded automatically (~79MB). Subsequent runs will use the cached model.

### 4. Run Workflow

Run the non-deterministic multi-agent workflow:

```bash
source venv/bin/activate
python demo_agent_workflow.py
```

**Standard Mode (Hardcoded Tool Selection):**
- Agents use predefined logic to select tools
- Fast and reliable for known file types
- Default behavior

**Dynamic Tool Discovery Mode:**

Enable dynamic tool discovery where agents query the MCP server for available tools and use LLM reasoning to select the appropriate tool:

```bash
python demo_agent_workflow.py --discover-tools
```

**What Dynamic Mode Does:**
- ğŸ” Agents query MCP server via `tools/list` to discover available tools and their schemas
- ğŸ¤– LLM uses discovered tool information (descriptions, parameters) to intelligently select tools
- ğŸ“‹ Tool selection based on file types, patterns, and tool capabilities
- âœ… All tool calls still validated against hardcoded `ALLOWED_TOOLS` allowlist (security unchanged)
- ğŸ“Š Verbose logging shows discovery process and tool selection reasoning

**Example Output in Discovery Mode:**
```
ğŸ” Tool Discovery Mode: ENABLED
ğŸ” Discovering ingestion tools from MCP server...
   Found 12 total tools from server
   Discovered 6 ingestion tools:
     â€¢ ingest_excel: Ingest Excel (.xlsx) file...
     â€¢ ingest_csv: Ingest CSV file...
ğŸ¤– Using LLM to select tools based on discovered tool schemas...
   LLM tool selection results:
     âœ“ financials_Q3_2025.xlsx â†’ ingest_excel (priority: 1)
     âœ“ edgar_xbrl_q3_2025.csv â†’ ingest_edgar_xbrl (priority: 1)
```

**Features:**
- âœ… Adaptive retry logic (up to 2 retries)
- âœ… Conditional routing based on validation results
- âœ… Fallback mechanisms for failures
- âœ… Transparent path logging
- âœ… Intelligent tool selection (hardcoded or LLM-powered via `--discover-tools`)
- âœ… Dynamic tool discovery (optional, enables LLM reasoning about tool selection)

### 5. View the Generated One-Pager with Streamlit

Use the bundled Streamlit app to view the markdown one-pager in a formatted, interactive browser interface:

**Install Streamlit (if not already installed):**
```bash
source venv/bin/activate
pip install streamlit
```

**Run the Streamlit app:**
```bash
streamlit run app.py
```

This will:
- ğŸŒ Automatically open your default browser
- ğŸ“„ Display the formatted one-pager at `output/LP_OnePager_Acme_Software_Inc_2025_09_30_agent.md`
- ğŸ¨ Render markdown with proper formatting (tables, bullets, HTML)
- ğŸ’¾ Provide a download button for the markdown file
- ğŸ“‹ Show raw markdown code in an expandable section

**View a Different File:**
```bash
streamlit run app.py -- /path/to/your/onepager.md
```

**Access the App:**
- Default URL: `http://localhost:8501`
- If port 8501 is in use, Streamlit will use the next available port (8502, 8503, etc.)
- The URL will be displayed in the terminal output

**Features:**
- âœ… Formatted markdown rendering with HTML support
- âœ… Expandable source links (click "ğŸ“Š View sources" in tables)
- âœ… Download button for markdown file
- âœ… Raw markdown code viewer
- âœ… File path displayed at top

---

## ğŸ¤– Multi-Agent Architecture

The system uses a **multi-agent architecture** powered by **LangGraph** with three specialized agents:

### Architecture Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agents (Python/LangGraph)                              â”‚
â”‚  - IngestionAgent                                       â”‚
â”‚  - KPIComputationAgent                                  â”‚
â”‚  - ContentGenerationAgent                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
         (MCP protocol calls via HTTP/JSON-RPC)
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MCP Server (TypeScript)                                â”‚
â”‚  - Exposes tools via MCP protocol                       â”‚
â”‚  - Session management                                   â”‚
â”‚  - Tool validation                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
            (executes tools)
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MCP Tools                                              â”‚
â”‚  - ingest_excel, ingest_csv, ingest_memo               â”‚
â”‚  - compute_kpis                                         â”‚
â”‚  - get_golden_facts, render_onepager_markdown          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
         (interacts with data sources)
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Sources                                           â”‚
â”‚  - Files (Excel, CSV, TXT, MD)                         â”‚
â”‚  - PostgreSQL Database (with pgvector)                  â”‚
â”‚  - APIs (future: Stripe, Zuora, Snowflake)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agent Roles

#### 1. **IngestionAgent**
- Automatically discovers data files
- Determines optimal ingestion order (LLM-powered, configurable via `LLM_MODEL`)
- Retries failed ingestions with alternative strategies
- Validates ingestion results

#### 2. **KPIComputationAgent**
- Validates data quality before computation
- Determines optimal KPI parameters (LLM-powered, configurable via `LLM_MODEL`)
- Computes KPIs with validation
- Falls back to existing KPIs if computation fails

#### 3. **ContentGenerationAgent**
- Analyzes financial trends
- Generates investment thesis and risks using LLM (configurable via `LLM_MODEL`)
- Validates content quality
- Falls back to default content if generation fails

### Non-Deterministic Workflow

The workflow uses **conditional routing** to adapt to different conditions:

- **After Ingestion**: Routes to `continue`, `retry` (up to 2x), or `skip` based on validation
- **After KPI Computation**: Routes to `continue` or `fallback` based on results
- **After Content Generation**: Routes to `continue` or `fallback_content` based on validation

See [PRD.md](prd.md) for detailed architecture documentation.

---

## ğŸ› ï¸ Installation

### Node.js Dependencies

```bash
npm install
```

### Python Dependencies

```bash
source venv/bin/activate
pip install -r requirements.txt
```

**Required Python packages:**
- `langchain`, `langchain-openai`, `langgraph` - Agent framework
- `chromadb`, `sentence-transformers` - Local embeddings
- `httpx`, `aiohttp` - HTTP client for MCP protocol
- `pg` (psycopg2-binary) - PostgreSQL client
- `python-dotenv` - Environment variable management

---

## ğŸ“– Documentation

- **[PRD.md](prd.md)** - Complete Product Requirements Document
  - System architecture
  - Multi-agent workflow details
  - MCP protocol usage
  - Vector search & semantic retrieval
  - Tool specifications

- **[agents/README.md](agents/README.md)** - Agent implementation details

---

## ğŸ” Key Features

### Local Vector Embeddings
- Uses ChromaDB's built-in embedding model (`sentence-transformers/all-MiniLM-L6-v2`)
- No API keys required for embeddings
- Runs entirely locally (~79MB model download)

### Multi-Agent Workflow
- Specialized agents for ingestion, computation, and content generation
- LLM-powered decision-making
- **Dynamic tool discovery** (optional): Agents query MCP server and use LLM reasoning to select tools
- Automatic retry and fallback mechanisms
- Quality validation at each step

### MCP Protocol
- Standardized JSON-RPC interface
- Session management
- Tool discovery and validation (`tools/list` method)
- Dynamic tool discovery mode (agents query server for available tools)
- Streaming support

### Traceability
- Full lineage tracking from source cells to KPIs
- Expandable source links in markdown output
- Audit trail for all generated artifacts

---

## ğŸ“Š Verify Installation

Check that KPIs are computed:

```sql
SELECT k.name, kv.value, kv.unit
FROM golden_facts gf
JOIN kpi_values kv USING (kpi_value_id)
JOIN kpis k USING (kpi_id)
WHERE gf.deal_id = '00000000-0000-0000-0000-000000000001'
  AND gf.status = 'approved';
```

---

## ğŸš€ Example Output

The workflow generates markdown one-pagers with:
- Formatted financial metrics ($4.97 M USD, 28.4%, etc.)
- Investment thesis section with expandable sources
- Key risks & mitigants section with expandable sources
- Full lineage traceability

Example output: `output/LP_OnePager_Acme_Software_Inc_2025_09_30_agent.md`

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ agents/                    # Multi-agent system
â”‚   â”œâ”€â”€ ingestion_agent.py    # Data ingestion agent
â”‚   â”œâ”€â”€ kpi_agent.py          # KPI computation agent
â”‚   â”œâ”€â”€ content_agent.py      # Content generation agent
â”‚   â”œâ”€â”€ workflow_graph.py     # LangGraph workflow (deterministic)
â”‚   â””â”€â”€ nondet_workflow_graph.py  # LangGraph workflow (non-deterministic)
â”œâ”€â”€ data/                     # Sample data files
â”œâ”€â”€ scripts/                   # Utility scripts
â”œâ”€â”€ sql/                       # Database schema and seeds
â”œâ”€â”€ mcp-lp-tools-server.ts    # MCP server (TypeScript)
â”œâ”€â”€ demo_agent_workflow.py     # Multi-agent workflow demo (recommended)
â”œâ”€â”€ prd.md                     # Product Requirements Document
â””â”€â”€ README.md                  # This file
```

---

## ğŸ”§ Troubleshooting

### MCP Server Not Reachable
Ensure the server is running:
```bash
npx tsx mcp-lp-tools-server.ts
```

### OpenAI API Key Issues
- Set `OPENAI_API_KEY` in `.env` file
- Or export: `export OPENAI_API_KEY=your_key`
- If not set, system uses fallback content (still works!)
- Configure LLM model via `LLM_MODEL` env var (default: `gpt-3.5-turbo`)
- All agents use the same model configured in `LLM_MODEL`

### Import Errors
Ensure all dependencies are installed:
```bash
pip install -r requirements.txt
```

### Database Connection Issues
Ensure Docker is running and database is up:
```bash
docker compose up -d
```

---

## ğŸ“ License

See LICENSE file for details.

---

## ğŸ¤ Contributing

See PRD.md for architecture and design decisions.
